#!/usr/bin/env python
import csv
import math
import sys
import time

import roslib; roslib.load_manifest('kitchen_data_player')
import rospy
import tf
from tf.transformations import quaternion_from_euler

from geometry_msgs.msg import Pose
from geometry_msgs.msg import PoseStamped
from geometry_msgs.msg import PoseArray

# This script parses poses.csv and labels.csv of the TUM kitchen dataset and creates a new csv-file that contains positions, labels
# and timestamps of poses where the human stood still and interacted with objects
# Here we only consider poses where the labels change in a way that "ReleaseAnObject" must be preceeded by NOT "ReleaseAnObject" and so on
# Also Object positions are calculated for those positions and their orientation is calculated from the pose of the humans hand at the
# specific time towards the human position

# Usage: stationary_kitchen_data.py poses.csv labels.csv output.csv

# This function checks in which cluster the given point is and assigns the correct location to it. The multivariate gaussians are hardcoded here and generated by WEKA
def get_cluster_number(x, y):
    
    x = x * 1000
    y = y * 1000

    # Those are the hardcoded gaussians from WEKA
    p1 = math.exp( - ( (((x - 971.8) * (x - 971.8)) / (2 * 77.2 * 77.2)) + ((y - 2619.5) * (y - 2619.5)) / (2 * 98.55 * 98.55)))
    p2 = math.exp( - ( (((x - 2174.9577) * (x - 2174.9577)) / (2 * 91.9 * 91.9)) + ((y - 2643.1) * (y - 2643.1)) / (2 * 107.5 * 107.5)))
    p3 = math.exp( - ( (((x - 763.71) * (x - 763.71)) / (2 * 61.9 * 61.9)) + ((y - 2173.98) * (y - 2173.98)) / (2 * 136.96 * 136.96))) 
    p4 = math.exp( - ( (((x -778.4352) * (x - 778.4352)) / (2 * 70.6725 * 70.6725)) + ((y - 3215.1622) * (y - 3215.1622)) / (2 * 72.6388 * 72.6388)))

    cluster = -1
    location = ''

    if p1 > p2 and p1 > p3 and p1 > p4:
        cluster = 1
        location = 'drawer'
        print("Human is in cluster %s with prob: %s"%(location, p1))
    elif p2 > p1 and p2 > p3 and p2 > p4:
        cluster = 2
        location = 'table'
        print("Human is in cluster %s with prob: %s"%(location, p2))
    elif p3 > p1 and p3 > p2 and p3 > p4:
        cluster = 3
        location = 'stove'
        print("Human is in cluster %s with prob: %s"%(location, p3))
    elif p4 > p1 and p4 > p2 and p4 > p3:
        cluster = 4
        location = 'cupboard'
        print("Human is in cluster %s with prob: %s"%(location, p4))
    else:
        cluster = -1
        location = 'none'
        print("WARNING, could not find location of that object (p1,p2,p3,p4): %s, %s, %s, %s"%(p1, p2, p3, p4))
    return cluster, location

# publishes the mean-values of the gaussians for the human positino
def publish_gaussians():
    # Use TF to calculate relative area definitions
    br.sendTransform((0.9718, 2.6195, 0),
                     quaternion_from_euler(0,0,3.1415) ,
                     rospy.Time.now(),
                     "drawer_gaussian_mean",
                     "map")

    br.sendTransform((2.17495, 2.6431, 0),
                     quaternion_from_euler(0,0,0) ,
                     rospy.Time.now(),
                     "table_gaussian_mean",
                     "map")
    
    br.sendTransform((0.76371, 2.17398, 0),
                     quaternion_from_euler(0,0,3.1415) ,
                     rospy.Time.now(),
                     "stove_gaussian_mean",
                     "map")

    br.sendTransform((0.77843, 3.21516, 0),
                     quaternion_from_euler(0,0,3.1415) ,
                     rospy.Time.now(),
                     "cupboard_gaussian_mean",
                     "map")

def publish_kinect():
    kinect_x = 1.3175
    kinect_y = 0.0946

    br.sendTransform((kinect_x, kinect_y, 0),
                     quaternion_from_euler(0,0,1.57075) ,
                     rospy.Time.now(),
                     "kinect",
                     "map")

# Publishes the (hard-coded) locations of the furniture using tf
def publish_furniture():

    #br = tf.TransformBroadcaster()
    # Furniture

    # from logged object data
    plate_x = 2.60843
    plate_y = 2.62942
    plate_theta = 3.1415
    
    # from semantic map
    table_x = 2.78
    table_y = 2.29
    table_theta = -1.5707963705062866
    table_depth = 0.8
    table_theta = 1.57075

    # from logged object data
    placemat_x = 0.3815425
    placemat_y = 2.0313084
    placemat_theta = 0
    
    # from sematic map
    stove_x = 0.32918193
    stove_y = 1.9835850
    stove_theta = 0
    stove_depth = 0.5766061

    # from semantic map
    drawer_x = 0.32296494
    drawer_y = 2.530835
    drawer_theta = 0
    drawer_depth = 0.5641721

    # from semantic map
    cupboard_x = 0.19635946
    cupboard_y = 3.107985
    cupboard_theta = 0
    cupboard_depth = 0.3109611

    br.sendTransform((table_x, table_y, 0),
                     tf.transformations.quaternion_from_euler(0, 0, table_theta),
                     rospy.Time.now(),
                     "table",
                     "map")
                     
    br.sendTransform((0, table_depth/2, 0),
                     tf.transformations.quaternion_from_euler(0, 0, 0),
                     rospy.Time.now(),
                     "table_edge",
                     "table")
    
    br.sendTransform((plate_x, plate_y, 0),
                     tf.transformations.quaternion_from_euler(0, 0, plate_theta),
                     rospy.Time.now(),
                     "plate",
                     "map")

    br.sendTransform((drawer_x, drawer_y, 0),
                     tf.transformations.quaternion_from_euler(0, 0, drawer_theta),
                     rospy.Time.now(),
                     "drawer",
                     "map")
    
    # Edge of drawer as reference to where human is standing                 
    br.sendTransform((drawer_depth/2, 0, 0),
                     tf.transformations.quaternion_from_euler(0, 0, 0),
                     rospy.Time.now(),
                     "drawer_edge",
                     "drawer")

    br.sendTransform((stove_x, stove_y, 0),
                     tf.transformations.quaternion_from_euler(0, 0, stove_theta),
                     rospy.Time.now(),
                     "stove",
                     "map")
                     
    # object that is on the stove
    br.sendTransform((placemat_x, placemat_y, 0),
                     tf.transformations.quaternion_from_euler(0, 0, placemat_theta),
                     rospy.Time.now(),
                     "placemat",
                     "map")
    
    br.sendTransform((stove_depth/2, 0, 0),
                     tf.transformations.quaternion_from_euler(0, 0, stove_theta),
                     rospy.Time.now(),
                     "stove_edge",
                     "stove")

    br.sendTransform((cupboard_x, cupboard_y, 0),
                     tf.transformations.quaternion_from_euler(0, 0, cupboard_theta),
                     rospy.Time.now(),
                     "cupboard",
                     "map")
                    
    br.sendTransform((cupboard_depth/2, 0, 0),
                     tf.transformations.quaternion_from_euler(0, 0, 0),
                     rospy.Time.now(),
                     "cupboard_edge",
                     "cupboard")
    try:
        now = rospy.Time.now() - rospy.Duration(0.0)
        tf_listener.waitForTransform("stove_edge", "placemat", rospy.Time(0), rospy.Duration(0.001))
        (placemat_trans, placemat_rot) = tf_listener.lookupTransform("stove_edge", "placemat", rospy.Time(0))
        tf_listener.waitForTransform("table_edge", "plate", rospy.Time(0), rospy.Duration(0.001))
        (plate_trans, plate_rot) = tf_listener.lookupTransform("table_edge", "plate", rospy.Time(0))
        #print("Trans: %s, %s, %s"%(trans[0], trans[1], trans[2]))
        
        br.sendTransform((0, placemat_trans[1], 0),
                     tf.transformations.quaternion_from_euler(0, 0, 0),
                     rospy.Time.now(),
                     "placemat_edge",
                     "stove_edge")
                     
        br.sendTransform((plate_trans[0], 0, 0),
                     tf.transformations.quaternion_from_euler(0, 0, plate_theta - table_theta),
                     rospy.Time.now(),
                     "plate_edge",
                     "table_edge")
    except (tf.Exception, tf.LookupException, tf.ConnectivityException):
        print('.')

            
posesReader = csv.DictReader(open(sys.argv[1], 'rb'), delimiter=',', quotechar='|')

# Init ROSnode
pose_pub = rospy.Publisher('kitchen_pose', PoseStamped)             # current pose

rospy.init_node('kitchen_player')

br = tf.TransformBroadcaster()
tf_listener = tf.TransformListener()
global_x = 0
global_y = 0

for row in posesReader:
    publish_furniture()
    publish_gaussians()
    publish_kinect()

    #TODO: include and calculate orientation
    theta = 0
    
    
   

    quat = quaternion_from_euler(0,0,0)
    br.sendTransform((float(row['z']), float(row['x']), 0),
                     quat,
                     rospy.Time.now(),
                     "human_pose",
                     "kinect")

    # get human position in reference to map
    try:
        now = rospy.Time.now() - rospy.Duration(0.0)
        tf_listener.waitForTransform("map", "human_pose", rospy.Time(0), rospy.Duration(0.001))
        (human_trans, human_rot) = tf_listener.lookupTransform("map", "human_pose", rospy.Time(0))
        global_x = human_trans[0]
        global_y = human_trans[1]
        print("humantrans: x: %s, y: %s"%(human_trans[0], human_trans[1]))
       
    except (tf.Exception, tf.LookupException, tf.ConnectivityException):
        print('.')

    get_cluster_number(global_x, global_y)
    
    #time.sleep(0.033) #realtime
    time.sleep(0.005)
    

