#!/usr/bin/env python
import csv
import math
import sys
import time

import roslib; roslib.load_manifest('kitchen_data_player')
import rospy
import tf
from tf.transformations import quaternion_from_euler

from geometry_msgs.msg import Pose
from geometry_msgs.msg import PoseStamped
from geometry_msgs.msg import PoseArray

# This script parses poses.csv and labels.csv of the TUM kitchen dataset and creates a new csv-file that contains positions, labels
# and timestamps of poses where the human stood still and interacted with objects
# Here we only consider poses where the labels change in a way that "ReleaseAnObject" must be preceeded by NOT "ReleaseAnObject" and so on
# Also Object positions are calculated for those positions and their orientation is calculated from the pose of the humans hand at the
# specific time towards the human position

# Usage: stationary_kitchen_data.py poses.csv labels.csv output.csv

# This function checks in which cluster the given point is and assigns the correct location to it. The multivariate gaussians are hardcoded here and generated by WEKA
def get_cluster_number(x, y):
    
    x = x * 1000
    y = y * 1000

    # Those are the hardcoded gaussians from WEKA
    p1 = math.exp( - ( (((x - 971.8) * (x - 971.8)) / (2 * 77.2 * 77.2)) + ((y - 2619.5) * (y - 2619.5)) / (2 * 98.55 * 98.55)))
    p2 = math.exp( - ( (((x - 2174.9577) * (x - 2174.9577)) / (2 * 91.9 * 91.9)) + ((y - 2643.1) * (y - 2643.1)) / (2 * 107.5 * 107.5)))
    p3 = math.exp( - ( (((x - 763.71) * (x - 763.71)) / (2 * 61.9 * 61.9)) + ((y - 2173.98) * (y - 2173.98)) / (2 * 136.96 * 136.96))) 
    p4 = math.exp( - ( (((x -778.4352) * (x - 778.4352)) / (2 * 70.6725 * 70.6725)) + ((y - 3215.1622) * (y - 3215.1622)) / (2 * 72.6388 * 72.6388)))

    cluster = -1
    location = ''

    if p1 > p2 and p1 > p3 and p1 > p4:
        cluster = 1
        location = 'drawer'
    if p2 > p1 and p2 > p3 and p2 > p4:
        cluster = 2
        location = 'table'
    if p3 > p1 and p3 > p2 and p3 > p4:
        cluster = 3
        location = 'stove'
    if p4 > p1 and p4 > p2 and p4 > p3:
        cluster = 4
        location = 'cupboard'

    return cluster, location

# Publishes the (hard-coded) locations of the furniture using tf
def publish_furniture():

    #br = tf.TransformBroadcaster()
    # Furniture

    # from logged object data
    plate_x = 2.60843
    plate_y = 2.62942
    plate_theta = 3.1415
    
    # from semantic map
    table_x = 2.0
    table_y = 3.2
    table_theta = -1.5707963705062866
    #table_theta = 0

    # from logged object data
    placemat_x = 0.358843
    placemat_y = 2.128373
    placemat_theta = 0
    
    # from sematic map
    stove_x = 0.32918193
    stove_y = 1.9835850
    stove_theta = 0
    stove_depth = 0.5766061

    # from semantic map
    drawer_x = 0.32296494
    drawer_y = 2.530835
    drawer_theta = 0
    drawer_depth = 0.5641721

    # from semantic map
    cupboard_x = 0.19635946
    cupboard_y = 3.107985
    cupboard_theta = 0
    cupboard_depth = 0.3109611

    br.sendTransform((table_x, table_y, 0),
                     tf.transformations.quaternion_from_euler(0, 0, table_theta),
                     rospy.Time.now(),
                     "table",
                     "map")
    
    br.sendTransform((plate_x, plate_y, 0),
                     tf.transformations.quaternion_from_euler(0, 0, plate_theta),
                     rospy.Time.now(),
                     "plate",
                     "map")

    br.sendTransform((drawer_x, drawer_y, 0),
                     tf.transformations.quaternion_from_euler(0, 0, drawer_theta),
                     rospy.Time.now(),
                     "drawer",
                     "map")
    
    # Edge of drawer as reference to where human is standing                 
    br.sendTransform((drawer_depth/2, 0, 0),
                     tf.transformations.quaternion_from_euler(0, 0, 0),
                     rospy.Time.now(),
                     "drawer_edge",
                     "drawer")

    br.sendTransform((stove_x, stove_y, 0),
                     tf.transformations.quaternion_from_euler(0, 0, stove_theta),
                     rospy.Time.now(),
                     "stove",
                     "map")
                     
    # object that is on the stove
    br.sendTransform((placemat_x, placemat_y, 0),
                     tf.transformations.quaternion_from_euler(0, 0, placemat_theta),
                     rospy.Time.now(),
                     "placemat",
                     "map")
    
    br.sendTransform((stove_depth/2, 0, 0),
                     tf.transformations.quaternion_from_euler(0, 0, stove_theta),
                     rospy.Time.now(),
                     "stove_edge",
                     "stove")

    br.sendTransform((cupboard_x, cupboard_y, 0),
                     tf.transformations.quaternion_from_euler(0, 0, cupboard_theta),
                     rospy.Time.now(),
                     "cupboard",
                     "map")
                    
    br.sendTransform((cupboard_depth/2, 0, 0),
                     tf.transformations.quaternion_from_euler(0, 0, 0),
                     rospy.Time.now(),
                     "cupboard_edge",
                     "cupboard")
    try:
        now = rospy.Time.now() - rospy.Duration(0.0)
        tf_listener.waitForTransform("stove_edge", "placemat", rospy.Time(0), rospy.Duration(0.001))
        (trans, rot) = tf_listener.lookupTransform("stove_edge", "placemat", rospy.Time(0))
        #print("Trans: %s, %s, %s"%(trans[0], trans[1], trans[2]))
        
        br.sendTransform((0, trans[1], 0),
                     tf.transformations.quaternion_from_euler(0, 0, 0),
                     rospy.Time.now(),
                     "placemat edge",
                     "stove_edge")
    except (tf.Exception, tf.LookupException, tf.ConnectivityException):
        print('.')

            
posesReader = csv.DictReader(open(sys.argv[1], 'rb'), delimiter=',', quotechar='|')
labelsReader = csv.DictReader(open(sys.argv[2], 'rb'), delimiter=',', quotechar='|')

FILE = open(sys.argv[3],"w")
FILE.write("instance,time,OBJX,OBJY,OBJTHETA,cluster,location\n") 

# Init ROSnode
pose_pub = rospy.Publisher('kitchen_pose', PoseStamped)             # current pose
poses_pub = rospy.Publisher('kitchen_poses', PoseArray)             # all poses
obj_pub = rospy.Publisher('object_poses', PoseArray)                # object positions

rospy.init_node('kitchen_player')

human_positions = PoseArray()                     # array to store the poses of the human for display
obj_positions = PoseArray()                       # array to store object positions for display
human_positions.header.frame_id = 'map'
obj_positions.header.frame_id = 'map'
last_lefthand = 'start'
last_righthand = 'start'
br = tf.TransformBroadcaster()
tf_listener = tf.TransformListener()

for row in posesReader:
    publish_furniture()
    #time.sleep(1/2)
    # Write new csv-file with: instance, time, BECX, BEXY, BECTheta, 
    theta = 0
    # Calculate theta
    instance = row['instance']
    x = float(row['SBRX']) - float(row['SBLX'])
    y = float(row['SBRY']) - float(row['SBLY'])
    #theta = math.atan2(-y, x)
    theta = math.atan2(x, -y)
    trunk = 'NONE'
    lefthand = 'NONE'
    righthand = 'NONE'

    quat = quaternion_from_euler(0,0,theta)
    br.sendTransform((float(row['BECX'])/1000, float(row['BECY'])/1000, 0),
                     quat,
                     rospy.Time.now(),
                     "human_pose",
                     "map")

    for labelrow in labelsReader:
        labelsReader = csv.DictReader(open(sys.argv[2], 'rb'), delimiter=',', quotechar='|')
        if instance == labelrow['instance']:
            lefthand = labelrow['lefthand']
            righthand = labelrow['righthand']
            trunk = labelrow['trunk']
             
    # Calculate Human position when standing still and interacting with objects
    if trunk == 'StandingStill'\
                 and (((lefthand == 'TakingSomeThing' and last_lefthand != 'TakingSomeThing') \
                 or (lefthand == 'ReleasingGraspOfSomething' and last_lefthand != 'ReleasingGraspOfSomething' and last_lefthand != 'ClosingADoor')) \
                 or ((righthand == 'TakingSomething' and last_righthand !=  'TakingSomething') \
                 or (righthand == 'ReleasingGraspOfSomething' and last_righthand !='ReleasingGraspOfSomething' and last_righthand != 'ClosingADoor'))):
        
        # Publish information on ROS-topics on the fly
        pose = PoseStamped()
        pose.header.frame_id = 'map'
        pose.pose.position.x = float(row['BECX'])/1000 # convert to meters here
        pose.pose.position.y = float(row['BECY'])/1000 # convert to meters here
        quat = quaternion_from_euler(0,0,theta)
        pose.pose.orientation.x = float(quat[0])
        pose.pose.orientation.y = float(quat[1])
        pose.pose.orientation.z = float(quat[2])
        pose.pose.orientation.w = float(quat[3])

        human_positions.poses.append(pose.pose)
        
        #print("TF from table: %s, %s"%tf_listener.lookupTransform("human_pose", "table", rospy.Time(0)))
        poses_pub.publish(human_positions)
        pose_pub.publish(pose)

    # Calculate object positions when grasping or releasing objects and calculate orientation of object to human (obj-pos looking at human body center)
    if trunk == 'StandingStill': 
        left = false
        right = false
        
        if ((lefthand == 'TakingSomething' and last_lefthand !=  'TakingSomething') \
                or (lefthand == 'ReleasingGraspOfSomething' and last_lefthand != 'ReleasingGraspOfSomething' and last_lefthand != 'ClosingADoor')): # Object interation with left hand
            obj_pose = Pose()
            obj_pose.position.x = float(row['HALX'])/1000
            obj_pose.position.y = float(row['HALY'])/1000

            # calculate object orientation using object position and human position (without orientation)
            # obj_quat = quaternion_from_euler(0,0,theta + 3.1415)
            deltax = pose.pose.position.x - obj_pose.position.x
            deltay = pose.pose.position.y - obj_pose.position.y
            obj_theta = math.atan2(deltay, deltax)
            obj_quat = quaternion_from_euler(0,0,obj_theta)
            
            obj_pose.orientation.x = float(obj_quat[0])
            obj_pose.orientation.y = float(obj_quat[1])
            obj_pose.orientation.z = float(obj_quat[2])
            obj_pose.orientation.w = float(obj_quat[3])
            obj_positions.poses.append(obj_pose)
            
            cluster, location = get_cluster_number(pose.pose.position.x, pose.pose.position.y)
            
            #print("LEFT hand used at instance = %s"%row['instance'])
            #print("last lefthand: %s, lefthand: %s"%(last_lefthand, lefthand))
            FILE.write("%s,%s,%s,%s,%s,%s,%s\n"%(instance, row['time'], row['HALX'], row['HALY'], obj_theta, cluster, location))
            print("Object position: %s,%s,%s,%s,%s,%s,%s"%(instance, row['time'], row['HALX'], row['HALY'], obj_theta, cluster, location))

        if ((righthand == 'TakingSomething' and last_righthand !=  'TakingSomething') \
                or (righthand == 'ReleasingGraspOfSomething' and last_righthand !='ReleasingGraspOfSomething' and last_righthand != 'ClosingADoor')): # Object interaction with right hand
            obj_pose = Pose()
            obj_pose.position.x = float(row['HARX'])/1000 
            obj_pose.position.y = float(row['HARY'])/1000

            # calculate object orientation using object position and human position (without orientation)
            # obj_quat = quaternion_from_euler(0,0,theta + 3.1415)
            deltax = pose.pose.position.x - obj_pose.position.x
            deltay = pose.pose.position.y - obj_pose.position.y
            obj_theta = math.atan2(deltay,deltax)
            obj_quat = quaternion_from_euler(0,0,obj_theta)

            obj_pose.orientation.x = float(obj_quat[0])
            obj_pose.orientation.y = float(obj_quat[1])
            obj_pose.orientation.z = float(obj_quat[2])
            obj_pose.orientation.w = float(obj_quat[3])
            obj_positions.poses.append(obj_pose)
            
            cluster, location = get_cluster_number(pose.pose.position.x, pose.pose.position.y)
            #print("RIGHT hand used at instance: = %s"%row['instance'])
            #print("last righthand: %s, righthand: %s"%(last_righthand, righthand))
            FILE.write("%s,%s,%s,%s,%s,%s,%s\n"%(instance, row['time'], row['HARX'], row['HARY'], obj_theta, cluster, location))
            print("Object position: %s,%s,%s,%s,%s,%s,%s"%(instance, row['time'], row['HARX'], row['HARY'], obj_theta, cluster, location))
            
        obj_pub.publish(obj_positions)
        last_lefthand = lefthand
        last_righthand = righthand
        

